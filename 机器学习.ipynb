{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鸢尾花数据集:\n",
      " {'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': '/usr/local/lib/python3.6/dist-packages/sklearn/datasets/data/iris.csv'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "print('鸢尾花数据集:\\n',iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看数据集描述:\n",
      " .. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print('查看数据集描述:\\n',iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看特征值的名字:\n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print('查看特征值的名字:\\n',iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看特征值：\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]] (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print('查看特征值：\\n',iris.data,iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的特征值：\n",
      " [[4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [7.7 3.8 6.7 2.2]] (120, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#将数据集划分成训练用和测试用两部分\n",
    "#参数传入数据集的特征值数据和目标值数据，测试集部分数据占比test_size，随机数种子\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris.data,\n",
    "                                                 iris.target,\n",
    "                                                 test_size=0.2,\n",
    "                                                random_state=22\n",
    "                                                )\n",
    "print('训练集的特征值：\\n',x_train,x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一步：特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 字典数据特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f7aa78fd775f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#语法：\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#实例化转换器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#spars指定使用稀疏矩阵\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#将字典数据特征值化，返回稀疏矩阵\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "#语法：\n",
    "#实例化转换器\n",
    "sklearn.feature_extraction.DictVectorizer(spars=True)  #spars指定使用稀疏矩阵\n",
    "#将字典数据特征值化，返回稀疏矩阵\n",
    "DictVectorizer.fit_transform(X)\n",
    "#返回特征名字\n",
    "DictVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[0. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#案例\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "#原始数据\n",
    "data = [{'city':'北京','temperature':'100'},\n",
    "       {'city':'上海','temperature':'60'},\n",
    "       {'city':'深圳','temperature':'30'}]\n",
    "\n",
    "#1. 实例化一个转换器类\n",
    "transfer = DictVectorizer(sparse=False)\n",
    "#2. 调用fit_transform(),对字典数据进行特征值化\n",
    "data_new = transfer.fit_transform(data)\n",
    "print('data_new:\\n',data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征名称:\n",
      " ['city=上海', 'city=北京', 'city=深圳', 'temperature=100', 'temperature=30', 'temperature=60']\n"
     ]
    }
   ],
   "source": [
    "#查看特征名称\n",
    "print('特征名称:\\n',transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[0 1 1 1 0 1 1 0]\n",
      " [1 1 1 0 1 1 0 1]]\n",
      "特征名字:\n",
      " ['dislike', 'is', 'life', 'like', 'long', 'python', 'short', 'too']\n"
     ]
    }
   ],
   "source": [
    "#案例\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#原始文本数据\n",
    "data = ['life is short,i like python',\n",
    "        'life is too long,i dislike python'\n",
    "       ]\n",
    "\n",
    "#1. 实例化转换器类\n",
    "transfer = CountVectorizer()\n",
    "#2. 调用fit_transform()生成文本特诊矩阵，统计每个样本特诊词出现的个数\n",
    "data_new = transfer.fit_transform(data)\n",
    "print('data_new:\\n',data_new.toarray())    #使用toarray将稀疏矩阵详细显示\n",
    "#3. 查看特诊名字\n",
    "print('特征名字:\\n',transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是', '我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ，']\n",
      "data_new:\n",
      " [[2 0 1 0 0 0 1 1 0 1 0 2 0 1 1 1]\n",
      " [0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0]]\n",
      "特征名字:\n",
      " ['一种', '之前', '今天', '光是在', '几百万年', '发出', '后天', '大部分', '我们', '明天', '星系', '残酷', '看到', '绝对', '美好', '还是']\n"
     ]
    }
   ],
   "source": [
    "#案例２：中文笨笨特征抽取，需要使用结巴分词拆分句子成词语\n",
    "import jieba\n",
    "\n",
    "def cut_word(text):\n",
    "    '''\n",
    "    使用结巴分词进行中文分词\n",
    "    :param text:\n",
    "    :return:\n",
    "    '''\n",
    "    text = ' '.join(list(jieba.cut(text)))\n",
    "    return text\n",
    "\n",
    "#中文文本数据\n",
    "data = ['一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是',\n",
    "       '我们看到的从很远星系来的光是在几百万年之前发出的，']\n",
    "\n",
    "data_new = []\n",
    "for sent in data:\n",
    "    data_new.append(cut_word(sent))\n",
    "print(data_new)\n",
    "\n",
    "#实例化一个转换器\n",
    "transfer = CountVectorizer()\n",
    "\n",
    "#调用fit_transform\n",
    "data_final = transfer.fit_transform(data_new)\n",
    "print('data_new:\\n',data_final.toarray())\n",
    "print('特征名字:\\n',transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是', '我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ，']\n",
      "data_new:\n",
      " [[0.51639778 0.         0.25819889 0.         0.         0.\n",
      "  0.25819889 0.25819889 0.         0.25819889 0.         0.51639778\n",
      "  0.         0.25819889 0.25819889 0.25819889]\n",
      " [0.         0.37796447 0.         0.37796447 0.37796447 0.37796447\n",
      "  0.         0.         0.37796447 0.         0.37796447 0.\n",
      "  0.37796447 0.         0.         0.        ]]\n",
      "特征名字:\n",
      " ['一种', '之前', '今天', '光是在', '几百万年', '发出', '后天', '大部分', '我们', '明天', '星系', '残酷', '看到', '绝对', '美好', '还是']\n"
     ]
    }
   ],
   "source": [
    "#案例３:tf-idf特征抽取\n",
    "#在某一个类别的文章中，某个词出现的次数很多，但是在其他类别的文章中出现很少，\n",
    "#这些词可以用来做分类文章\n",
    "#使用tf-idf算法计算出各个关键词的重要程度,数值越大说明越重要\n",
    "#api:TfidVectorizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#中文文本数据\n",
    "data = ['一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是',\n",
    "       '我们看到的从很远星系来的光是在几百万年之前发出的，']\n",
    "\n",
    "data_new = []\n",
    "for sent in data:\n",
    "    data_new.append(cut_word(sent))\n",
    "print(data_new)\n",
    "\n",
    "#实例化一个转换器\n",
    "transfer = TfidfVectorizer()\n",
    "\n",
    "#调用fit_transform\n",
    "data_final = transfer.fit_transform(data_new)\n",
    "print('data_new:\\n',data_final.toarray()) #toarray()将稀疏矩阵详细显示\n",
    "print('特征名字:\\n',transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二步：数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 均值移除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "均值移除：让样本矩阵的每一列的平均值为０，标准差为１\n",
    "api:A = sp.scale(array)　　　　#array为原数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.22474487  1.38873015 -1.33630621]\n",
      " [ 0.         -0.46291005  0.26726124]\n",
      " [ 1.22474487 -0.9258201   1.06904497]]\n",
      "\n",
      "\n",
      "[ 0.00000000e+00 -3.70074342e-17  5.18104078e-16]\n",
      "\n",
      "\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#案例\n",
    "import sklearn.preprocessing as sp\n",
    "import numpy as np\n",
    "\n",
    "raw_samples = np.array([\n",
    "    [17,100,4000],\n",
    "    [20,80,5000],\n",
    "    [23,75,5500]\n",
    "])\n",
    "\n",
    "std_samples = sp.scale(raw_samples)\n",
    "print(std_samples)\n",
    "print('\\n')\n",
    "print(std_samples.mean(axis=0))\n",
    "print('\\n')\n",
    "print(std_samples.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 范围缩放"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将样本矩阵中的每一列的最小值设为相同的区间，统一各列特征值的范围，\n",
    "一般情况下会把特征值缩放至[0,1]区间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "api:\n",
    "#创建MinMax缩放器\n",
    "mms = sp.MinMaxScale(feature_range=(0,1))\n",
    "#调用mms对象的方法执行缩放操作，返回缩放过后的结果\n",
    "result = mms.fit_transform(原始样本矩阵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#案例\n",
    "raw_samples = np.array([\n",
    "    [17,100,4000],\n",
    "    [20,80,5000],\n",
    "    [23,75,5500]\n",
    "])\n",
    "\n",
    "print(raw_samples)\n",
    "\n",
    "mms_samples = raw_samples.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 独热编码one hot encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为样本特征的每个值建立一个由一个１和若干个０组成的序列，\n",
    "用该序列对所有的特征值进行编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语法\n",
    "#创建一个独热编码器\n",
    "# sparse： 是否使用紧缩格式（稀疏矩阵）\n",
    "# dtyle：  数据类型\n",
    "ohe = sp.OneHotEncoder(sparse=是否采用紧缩格式, dtype=数据类型)\n",
    "# 对原始样本矩阵进行训练，得到编码字典\n",
    "encode_dict = ohe.fit(原始样本矩阵)\n",
    "# 调用encode_dict字典的transform方法 对数据样本矩阵进行独热编码\n",
    "result = encode_dict.transform(原始样本矩阵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#案例\n",
    "raw_samples = np.array([\n",
    "    [17., 100., 4000],\n",
    "    [20., 80., 5000],\n",
    "    [23., 75., 5500]])\n",
    "# 创建独热编码器\n",
    "ohe = sp.OneHotEncoder(sparse=False, dtype=int,categories='auto')\n",
    "# 用独特编码器对原始样本矩阵做独热编码\n",
    "ohe_dict = ohe.fit(raw_samples)\n",
    "ohe_samples = ohe_dict.transform(raw_samples)\n",
    "ohe_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_samples = ohe.fit_transform(raw_samples)\n",
    "ohe_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要用于处理小规模精确化数据\n",
    "为了让所有的特征的权重对结果的影响一致，\n",
    "将每一列的特征值转换成固定的区间内(经常为(0-1),也可以自己设定)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-56-b0e15a783e6a>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-56-b0e15a783e6a>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    data = data.iloc[]\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = pd.read_csv('文件路径')\n",
    "#查看dataframe的所有行＆前三列的数据\n",
    "data = data.iloc[:,:3]\n",
    "print('data:\\n',data)\n",
    "\n",
    "#1. 实例化一个转换器类\n",
    "transfer = MinMaxScaler(feature_range=[0,1])\n",
    "\n",
    "#2. 调用fit_transform进行归一化\n",
    "data_new = transfer.fit_transform(data)\n",
    "print('data_new:\\n',data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比归一化更为通用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将ndarray数组每一列数据都聚集在均值为0,标准差为１的附近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('文件路径')\n",
    "#查看dataframe的所有行＆前三列的数据\n",
    "data = data.iloc[:,:3]\n",
    "print('data:\\n',data)\n",
    "\n",
    "#1. 实例化一个转换器类\n",
    "transfer = StandardScaler(data)\n",
    "\n",
    "#2. 调用fit_transform进行标准化\n",
    "data_new = transfer.fit_transform(data)\n",
    "print('data_new:\\n',data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三步：特征降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法１：特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 特征选择的方法１:方差选择法(低方差特征过滤)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原理：当特征相近时，他们的方差也是相近的(接近于0)，通过过滤低方差达到特征选择的目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#1.读取数据\n",
    "pd.read_csv(\"csv数据文件\")\n",
    "#2.实例化一个转换器类\n",
    "transfer = VarianceThreshold(threshold=2)\n",
    "#3.调用fit_transform\n",
    "data_new = transfer.fit_transform(data)\n",
    "print('data_new:n',data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 特征选择的方法２：pearsonr相关系数法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数学原理：\n",
    "步骤１．使用皮尔孙相关系数，查看两个特征间的相关性(越接近-1表示负相关越大，越接近+1表示正相关越大)\n",
    "步骤２：使用PCA降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''计算pearsonr相关系数'''\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "r = pearsonr(data['特征列１','特征列２'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法２：主成分分析(pca降维)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[ 1.28620952e-15  3.82970843e+00]\n",
      " [ 5.74456265e+00 -1.91485422e+00]\n",
      " [-5.74456265e+00 -1.91485422e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#1.获取数据\n",
    "data = [[2,8,4,5],\n",
    "        [6,3,0,8],\n",
    "        [5,4,9,1]]\n",
    "#2. 实例化一个转换器类,将４个特征转为2个特征\n",
    "transfer = PCA(n_components=2)\n",
    "\n",
    "#3.调用fit_transform()\n",
    "data_new = transfer.fit_transform(data)\n",
    "print('data_new:\\n',data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ｐca降维案例：预测instacart超市用户下一步将会买哪些东西"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.数据准备：\n",
    "   1. 订单与商品信息表：order_products_prior.csv\n",
    "   字段:order_id,product_id\n",
    "   2. 商品信息表：products.csv表\n",
    "   字段：product_id,aisle_id(商品类别)\n",
    "   3. 用户订单信息表:orders.csv\n",
    "   字段：order_id,user_id\n",
    "   4. 商品所属具体物品类别表：aisles.csv\n",
    "   字段：aisle_id,aisle\n",
    "\n",
    "2.合并表：将user_id和aisle(商品类别)放到同一张表中，处理成：行索引为user_id,列索引为商品类别(特征)\n",
    "\n",
    "3.找到user_id和aisle(表示商品类别)之间的关系\n",
    "4.pca特征降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#1.获取数据\n",
    "order_products = pd.read_csv('order_productes_prior.csv')\n",
    "products = pd.read_csv('products.csv')\n",
    "orders = pd.read_csv('orders.csv')\n",
    "aisles = pd.read_csv('aisles.csv')\n",
    "\n",
    "#2.合并表，将字段user_id和aisle放到一张表中\n",
    "#因为products.csv表和aisles.csv表中都有aisle_id,先将这两个表合并\n",
    "tab1 = pd.merge(aisles,products,on='aisle_id')\n",
    "#然后tab1表和order_products表根据字段products_id合并(默认inner连接)\n",
    "tab2 = pd.merge(tab1,order_products,on='product_id')\n",
    "#最后tab2表和order_products表根据order_id字段合并，得到有user_id和aisle字段的表\n",
    "tab3 = pd.merge(tab2,orders,on='order_id')\n",
    "\n",
    "#3.找到user_id和aisle之间的关系,\n",
    "#使用交叉表,按照user_id,针对不同的aisle统计数量\n",
    "table = pd.crosstab(tab3['user_id'],tab3['aisle'])\n",
    "\n",
    "#4.pca降维\n",
    "from sklearn.decomposition import PCA\n",
    "#实例化转换器类,保留95%的数据\n",
    "transfer = PCA(n_components=0.95)\n",
    "#调用fit_transform\n",
    "data_new = transfer.fit_transform(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三步：使用机器学习算法进行训练获取模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### １．k-近邻算法\n",
    "优点：简单，易于理解\n",
    "缺点：需要选择好k值，属于懒惰算法，计算量大，时间复杂度高，只适合与小数据量使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### knn算法案例：对sklearn的鸢尾花数据集进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接比对真实值和预测值：\n",
      " [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True]\n",
      "准确率:\n",
      " 0.9473684210526315\n",
      "最佳参数:\n",
      " {'n_neighbors': 5}\n",
      "最佳结果:\n",
      " 0.9732142857142857\n",
      "最佳估计器：\n",
      " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "交叉验证结果:\n",
      " {'mean_fit_time': array([0.00074785, 0.00058436, 0.00043838, 0.00037799, 0.00046234,\n",
      "       0.00042078]), 'std_fit_time': array([4.73110502e-04, 3.03020541e-04, 1.38584090e-04, 5.12299561e-05,\n",
      "       3.37450548e-04, 1.19581901e-04]), 'mean_score_time': array([0.00307391, 0.00190549, 0.00121212, 0.00109873, 0.00109513,\n",
      "       0.00116651]), 'std_score_time': array([2.22851995e-03, 1.21863413e-03, 3.59040332e-04, 7.50393986e-05,\n",
      "       1.21867024e-04, 2.43258911e-04]), 'param_n_neighbors': masked_array(data=[1, 3, 5, 7, 9, 11],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}, {'n_neighbors': 7}, {'n_neighbors': 9}, {'n_neighbors': 11}], 'split0_test_score': array([1., 1., 1., 1., 1., 1.]), 'split1_test_score': array([0.91666667, 0.91666667, 1.        , 0.91666667, 0.91666667,\n",
      "       0.91666667]), 'split2_test_score': array([1., 1., 1., 1., 1., 1.]), 'split3_test_score': array([1.        , 1.        , 1.        , 1.        , 0.91666667,\n",
      "       1.        ]), 'split4_test_score': array([1., 1., 1., 1., 1., 1.]), 'split5_test_score': array([0.91666667, 0.91666667, 1.        , 1.        , 1.        ,\n",
      "       1.        ]), 'split6_test_score': array([0.90909091, 1.        , 0.90909091, 0.90909091, 0.90909091,\n",
      "       0.90909091]), 'split7_test_score': array([1., 1., 1., 1., 1., 1.]), 'split8_test_score': array([1., 1., 1., 1., 1., 1.]), 'split9_test_score': array([0.88888889, 0.77777778, 0.77777778, 0.77777778, 0.77777778,\n",
      "       0.77777778]), 'mean_test_score': array([0.96428571, 0.96428571, 0.97321429, 0.96428571, 0.95535714,\n",
      "       0.96428571]), 'std_test_score': array([0.04490364, 0.06465941, 0.06373749, 0.06518036, 0.06538389,\n",
      "       0.06518036]), 'rank_test_score': array([2, 2, 1, 2, 6, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#1. 获取鸢尾花数据集\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "#2. 使用sklearn划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris.data,\n",
    "                                                 iris.target,\n",
    "                                                 random_state=6)\n",
    "#3. 特征工程:标准化\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "transfer = StandardScaler()\n",
    "#对训练集进行标准化\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "#对测试集进行标准化\n",
    "x_test = transfer.transform(x_test)\n",
    "\n",
    "#4. knn算法预估器(算法)进行模型训练\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#生成预估器对象\n",
    "estimator = KNeighborsClassifier()\n",
    "#对k值进行调优：加入网格搜索和交叉验证\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#参数准备，给出预备的k值\n",
    "param_dict = {'n_neighbors':[1,3,5,7,9,11]}\n",
    "estimator = GridSearchCV(estimator,param_grid=param_dict,cv=10)\n",
    "#将训练集的特征值和目标值放进来进行训练\n",
    "estimator.fit(x_train,y_train)\n",
    "\n",
    "#5.模型评估\n",
    "#方法１：直接比对真实值和预测值\n",
    "#获取预测值\n",
    "y_predict = estimator.predict(x_test)\n",
    "#比对,返回True越多说明模型越成功\n",
    "print('直接比对真实值和预测值：\\n',y_test == y_predict)\n",
    "#方法２：计算准确率\n",
    "score = estimator.score(x_test,y_test)\n",
    "print('准确率:\\n',score)\n",
    "\n",
    "#最佳参数\n",
    "print('最佳参数:\\n',estimator.best_params_)\n",
    "#最佳结果\n",
    "print('最佳结果:\\n',estimator.best_score_)\n",
    "#最佳估计器\n",
    "print('最佳估计器：\\n',estimator.best_estimator_)\n",
    "#交叉验证结果\n",
    "print('交叉验证结果:\\n',estimator.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### knn算法案例：facebook签到数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>9.0809</td>\n",
       "      <td>54</td>\n",
       "      <td>470702</td>\n",
       "      <td>8523065625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.9567</td>\n",
       "      <td>4.7968</td>\n",
       "      <td>13</td>\n",
       "      <td>186555</td>\n",
       "      <td>1757726713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.3078</td>\n",
       "      <td>7.0407</td>\n",
       "      <td>74</td>\n",
       "      <td>322648</td>\n",
       "      <td>1137537235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.3665</td>\n",
       "      <td>2.5165</td>\n",
       "      <td>65</td>\n",
       "      <td>704587</td>\n",
       "      <td>6567393236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0961</td>\n",
       "      <td>1.1307</td>\n",
       "      <td>31</td>\n",
       "      <td>472130</td>\n",
       "      <td>7440663949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29118016</th>\n",
       "      <td>29118016</td>\n",
       "      <td>6.5133</td>\n",
       "      <td>1.1435</td>\n",
       "      <td>67</td>\n",
       "      <td>399740</td>\n",
       "      <td>8671361106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29118017</th>\n",
       "      <td>29118017</td>\n",
       "      <td>5.9186</td>\n",
       "      <td>4.4134</td>\n",
       "      <td>67</td>\n",
       "      <td>125480</td>\n",
       "      <td>9077887898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29118018</th>\n",
       "      <td>29118018</td>\n",
       "      <td>2.9993</td>\n",
       "      <td>6.3680</td>\n",
       "      <td>67</td>\n",
       "      <td>737758</td>\n",
       "      <td>2838334300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29118019</th>\n",
       "      <td>29118019</td>\n",
       "      <td>4.0637</td>\n",
       "      <td>8.0061</td>\n",
       "      <td>70</td>\n",
       "      <td>764975</td>\n",
       "      <td>1007355847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29118020</th>\n",
       "      <td>29118020</td>\n",
       "      <td>7.4523</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>17</td>\n",
       "      <td>102842</td>\n",
       "      <td>7028698129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29118021 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id       x       y  accuracy    time    place_id\n",
       "0                0  0.7941  9.0809        54  470702  8523065625\n",
       "1                1  5.9567  4.7968        13  186555  1757726713\n",
       "2                2  8.3078  7.0407        74  322648  1137537235\n",
       "3                3  7.3665  2.5165        65  704587  6567393236\n",
       "4                4  4.0961  1.1307        31  472130  7440663949\n",
       "...            ...     ...     ...       ...     ...         ...\n",
       "29118016  29118016  6.5133  1.1435        67  399740  8671361106\n",
       "29118017  29118017  5.9186  4.4134        67  125480  9077887898\n",
       "29118018  29118018  2.9993  6.3680        67  737758  2838334300\n",
       "29118019  29118019  4.0637  8.0061        70  764975  1007355847\n",
       "29118020  29118020  7.4523  2.0871        17  102842  7028698129\n",
       "\n",
       "[29118021 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#获取数据\n",
    "data = pd.read_csv('./heima_files/day02/data_FBlocation/train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>2.2360</td>\n",
       "      <td>1.3655</td>\n",
       "      <td>66</td>\n",
       "      <td>623174</td>\n",
       "      <td>7663031065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>2.2003</td>\n",
       "      <td>1.2541</td>\n",
       "      <td>65</td>\n",
       "      <td>610195</td>\n",
       "      <td>2358558474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>367</td>\n",
       "      <td>2.4108</td>\n",
       "      <td>1.3213</td>\n",
       "      <td>74</td>\n",
       "      <td>579667</td>\n",
       "      <td>6644108708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>874</td>\n",
       "      <td>2.0822</td>\n",
       "      <td>1.1973</td>\n",
       "      <td>320</td>\n",
       "      <td>143566</td>\n",
       "      <td>3229876087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1022</td>\n",
       "      <td>2.0160</td>\n",
       "      <td>1.1659</td>\n",
       "      <td>65</td>\n",
       "      <td>207993</td>\n",
       "      <td>3244363975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115112</th>\n",
       "      <td>29115112</td>\n",
       "      <td>2.1889</td>\n",
       "      <td>1.2914</td>\n",
       "      <td>168</td>\n",
       "      <td>721885</td>\n",
       "      <td>4606837364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115204</th>\n",
       "      <td>29115204</td>\n",
       "      <td>2.1193</td>\n",
       "      <td>1.4692</td>\n",
       "      <td>58</td>\n",
       "      <td>563389</td>\n",
       "      <td>2074133146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115338</th>\n",
       "      <td>29115338</td>\n",
       "      <td>2.0007</td>\n",
       "      <td>1.4852</td>\n",
       "      <td>25</td>\n",
       "      <td>765986</td>\n",
       "      <td>6691588909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115464</th>\n",
       "      <td>29115464</td>\n",
       "      <td>2.4132</td>\n",
       "      <td>1.4237</td>\n",
       "      <td>61</td>\n",
       "      <td>151918</td>\n",
       "      <td>7396159924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29117493</th>\n",
       "      <td>29117493</td>\n",
       "      <td>2.2948</td>\n",
       "      <td>1.0504</td>\n",
       "      <td>81</td>\n",
       "      <td>79569</td>\n",
       "      <td>1168869217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83197 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id       x       y  accuracy    time    place_id\n",
       "112            112  2.2360  1.3655        66  623174  7663031065\n",
       "180            180  2.2003  1.2541        65  610195  2358558474\n",
       "367            367  2.4108  1.3213        74  579667  6644108708\n",
       "874            874  2.0822  1.1973       320  143566  3229876087\n",
       "1022          1022  2.0160  1.1659        65  207993  3244363975\n",
       "...            ...     ...     ...       ...     ...         ...\n",
       "29115112  29115112  2.1889  1.2914       168  721885  4606837364\n",
       "29115204  29115204  2.1193  1.4692        58  563389  2074133146\n",
       "29115338  29115338  2.0007  1.4852        25  765986  6691588909\n",
       "29115464  29115464  2.4132  1.4237        61  151918  7396159924\n",
       "29117493  29117493  2.2948  1.0504        81   79569  1168869217\n",
       "\n",
       "[83197 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#案例中为了方便，缩小下数据集,只选取2<x<2.5 & 1<y<1.5之间的记录(工作中不需要)\n",
    "data = data.query('x > 2 & x < 2.5 & y > 1 & y <1.5')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1970-01-08 05:06:14', '1970-01-08 01:29:55',\n",
       "               '1970-01-07 17:01:07', '1970-01-02 15:52:46',\n",
       "               '1970-01-03 09:46:33', '1970-01-06 19:49:38',\n",
       "               '1970-01-06 13:33:24', '1970-01-02 22:49:55',\n",
       "               '1970-01-04 14:30:10', '1970-01-07 16:57:44',\n",
       "               ...\n",
       "               '1970-01-02 09:24:50', '1970-01-01 10:29:34',\n",
       "               '1970-01-09 11:38:46', '1970-01-02 03:42:14',\n",
       "               '1970-01-04 22:02:44', '1970-01-09 08:31:25',\n",
       "               '1970-01-07 12:29:49', '1970-01-09 20:46:26',\n",
       "               '1970-01-02 18:11:58', '1970-01-01 22:06:09'],\n",
       "              dtype='datetime64[ns]', name='time', length=83197, freq=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据处理思路：\n",
    "#1.将时间戳转为年月日\n",
    "dates = pd.to_datetime(data['time'],unit='s')\n",
    "dates = pd.DatetimeIndex(dates)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "      <th>place_id</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>2.2360</td>\n",
       "      <td>1.3655</td>\n",
       "      <td>66</td>\n",
       "      <td>623174</td>\n",
       "      <td>7663031065</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>2.2003</td>\n",
       "      <td>1.2541</td>\n",
       "      <td>65</td>\n",
       "      <td>610195</td>\n",
       "      <td>2358558474</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>367</td>\n",
       "      <td>2.4108</td>\n",
       "      <td>1.3213</td>\n",
       "      <td>74</td>\n",
       "      <td>579667</td>\n",
       "      <td>6644108708</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>874</td>\n",
       "      <td>2.0822</td>\n",
       "      <td>1.1973</td>\n",
       "      <td>320</td>\n",
       "      <td>143566</td>\n",
       "      <td>3229876087</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1022</td>\n",
       "      <td>2.0160</td>\n",
       "      <td>1.1659</td>\n",
       "      <td>65</td>\n",
       "      <td>207993</td>\n",
       "      <td>3244363975</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115112</th>\n",
       "      <td>29115112</td>\n",
       "      <td>2.1889</td>\n",
       "      <td>1.2914</td>\n",
       "      <td>168</td>\n",
       "      <td>721885</td>\n",
       "      <td>4606837364</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115204</th>\n",
       "      <td>29115204</td>\n",
       "      <td>2.1193</td>\n",
       "      <td>1.4692</td>\n",
       "      <td>58</td>\n",
       "      <td>563389</td>\n",
       "      <td>2074133146</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115338</th>\n",
       "      <td>29115338</td>\n",
       "      <td>2.0007</td>\n",
       "      <td>1.4852</td>\n",
       "      <td>25</td>\n",
       "      <td>765986</td>\n",
       "      <td>6691588909</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115464</th>\n",
       "      <td>29115464</td>\n",
       "      <td>2.4132</td>\n",
       "      <td>1.4237</td>\n",
       "      <td>61</td>\n",
       "      <td>151918</td>\n",
       "      <td>7396159924</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29117493</th>\n",
       "      <td>29117493</td>\n",
       "      <td>2.2948</td>\n",
       "      <td>1.0504</td>\n",
       "      <td>81</td>\n",
       "      <td>79569</td>\n",
       "      <td>1168869217</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83197 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id       x       y  accuracy    time    place_id  day  \\\n",
       "112            112  2.2360  1.3655        66  623174  7663031065    8   \n",
       "180            180  2.2003  1.2541        65  610195  2358558474    8   \n",
       "367            367  2.4108  1.3213        74  579667  6644108708    7   \n",
       "874            874  2.0822  1.1973       320  143566  3229876087    2   \n",
       "1022          1022  2.0160  1.1659        65  207993  3244363975    3   \n",
       "...            ...     ...     ...       ...     ...         ...  ...   \n",
       "29115112  29115112  2.1889  1.2914       168  721885  4606837364    9   \n",
       "29115204  29115204  2.1193  1.4692        58  563389  2074133146    7   \n",
       "29115338  29115338  2.0007  1.4852        25  765986  6691588909    9   \n",
       "29115464  29115464  2.4132  1.4237        61  151918  7396159924    2   \n",
       "29117493  29117493  2.2948  1.0504        81   79569  1168869217    1   \n",
       "\n",
       "          weekday  hour  \n",
       "112             3     5  \n",
       "180             3     1  \n",
       "367             2    17  \n",
       "874             4    15  \n",
       "1022            5     9  \n",
       "...           ...   ...  \n",
       "29115112        4     8  \n",
       "29115204        2    12  \n",
       "29115338        4    20  \n",
       "29115464        4    18  \n",
       "29117493        3    22  \n",
       "\n",
       "[83197 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将day ,weekday, hour添加到原始数据集中去\n",
    "data['day'] = dates.day\n",
    "data['weekday'] = dates.weekday\n",
    "data['hour'] = dates.hour\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "place_id\n",
       "1012165853     1\n",
       "1013991737     3\n",
       "1014605271    28\n",
       "1015645743     4\n",
       "1017236154    31\n",
       "              ..\n",
       "9988815170     1\n",
       "9992113332     1\n",
       "9993074125     2\n",
       "9994257798    25\n",
       "9996671132    18\n",
       "Name: row_id, Length: 2514, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#过滤掉签到次数少的地点(因为目的是分析签到多的location)\n",
    "#根据place_id进行分组聚合，查看各place_id的签到次数\n",
    "#并过滤掉签到次数row_id<4的place_id数据\n",
    "place_count = data.groupby('place_id').count()['row_id']\n",
    "place_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "      <th>place_id</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>2.2360</td>\n",
       "      <td>1.3655</td>\n",
       "      <td>66</td>\n",
       "      <td>623174</td>\n",
       "      <td>7663031065</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>367</td>\n",
       "      <td>2.4108</td>\n",
       "      <td>1.3213</td>\n",
       "      <td>74</td>\n",
       "      <td>579667</td>\n",
       "      <td>6644108708</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>874</td>\n",
       "      <td>2.0822</td>\n",
       "      <td>1.1973</td>\n",
       "      <td>320</td>\n",
       "      <td>143566</td>\n",
       "      <td>3229876087</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1022</td>\n",
       "      <td>2.0160</td>\n",
       "      <td>1.1659</td>\n",
       "      <td>65</td>\n",
       "      <td>207993</td>\n",
       "      <td>3244363975</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1045</td>\n",
       "      <td>2.3859</td>\n",
       "      <td>1.1660</td>\n",
       "      <td>498</td>\n",
       "      <td>503378</td>\n",
       "      <td>6438240873</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115112</th>\n",
       "      <td>29115112</td>\n",
       "      <td>2.1889</td>\n",
       "      <td>1.2914</td>\n",
       "      <td>168</td>\n",
       "      <td>721885</td>\n",
       "      <td>4606837364</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115204</th>\n",
       "      <td>29115204</td>\n",
       "      <td>2.1193</td>\n",
       "      <td>1.4692</td>\n",
       "      <td>58</td>\n",
       "      <td>563389</td>\n",
       "      <td>2074133146</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115338</th>\n",
       "      <td>29115338</td>\n",
       "      <td>2.0007</td>\n",
       "      <td>1.4852</td>\n",
       "      <td>25</td>\n",
       "      <td>765986</td>\n",
       "      <td>6691588909</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115464</th>\n",
       "      <td>29115464</td>\n",
       "      <td>2.4132</td>\n",
       "      <td>1.4237</td>\n",
       "      <td>61</td>\n",
       "      <td>151918</td>\n",
       "      <td>7396159924</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29117493</th>\n",
       "      <td>29117493</td>\n",
       "      <td>2.2948</td>\n",
       "      <td>1.0504</td>\n",
       "      <td>81</td>\n",
       "      <td>79569</td>\n",
       "      <td>1168869217</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80910 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id       x       y  accuracy    time    place_id  day  \\\n",
       "112            112  2.2360  1.3655        66  623174  7663031065    8   \n",
       "367            367  2.4108  1.3213        74  579667  6644108708    7   \n",
       "874            874  2.0822  1.1973       320  143566  3229876087    2   \n",
       "1022          1022  2.0160  1.1659        65  207993  3244363975    3   \n",
       "1045          1045  2.3859  1.1660       498  503378  6438240873    6   \n",
       "...            ...     ...     ...       ...     ...         ...  ...   \n",
       "29115112  29115112  2.1889  1.2914       168  721885  4606837364    9   \n",
       "29115204  29115204  2.1193  1.4692        58  563389  2074133146    7   \n",
       "29115338  29115338  2.0007  1.4852        25  765986  6691588909    9   \n",
       "29115464  29115464  2.4132  1.4237        61  151918  7396159924    2   \n",
       "29117493  29117493  2.2948  1.0504        81   79569  1168869217    1   \n",
       "\n",
       "          weekday  hour  \n",
       "112             3     5  \n",
       "367             2    17  \n",
       "874             4    15  \n",
       "1022            5     9  \n",
       "1045            1    19  \n",
       "...           ...   ...  \n",
       "29115112        4     8  \n",
       "29115204        2    12  \n",
       "29115338        4    20  \n",
       "29115464        4    18  \n",
       "29117493        3    22  \n",
       "\n",
       "[80910 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = data[data['place_id'].isin(place_count[place_count > 3].index.values)]\n",
    "data_final\n",
    "# isin(place_count(place_count > 3).index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选特征值和目标值\n",
    "#特征值\n",
    "x = data_final[['x','y','accuracy','day','weekday','hour']]\n",
    "#目标值\n",
    "y = data_final['place_id']\n",
    "#-------以上为数据清洗，获取特征值和目标值的部分------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23007922</th>\n",
       "      <td>2.4485</td>\n",
       "      <td>1.0138</td>\n",
       "      <td>77</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25785263</th>\n",
       "      <td>2.2503</td>\n",
       "      <td>1.3005</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18005463</th>\n",
       "      <td>2.0899</td>\n",
       "      <td>1.1891</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17892524</th>\n",
       "      <td>2.4850</td>\n",
       "      <td>1.4253</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356407</th>\n",
       "      <td>2.4246</td>\n",
       "      <td>1.2065</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573759</th>\n",
       "      <td>2.3887</td>\n",
       "      <td>1.3054</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17184298</th>\n",
       "      <td>2.3864</td>\n",
       "      <td>1.0222</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047468</th>\n",
       "      <td>2.3707</td>\n",
       "      <td>1.4906</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26133408</th>\n",
       "      <td>2.0718</td>\n",
       "      <td>1.1736</td>\n",
       "      <td>201</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23864929</th>\n",
       "      <td>2.3936</td>\n",
       "      <td>1.1778</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60682 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x       y  accuracy  day  weekday  hour\n",
       "23007922  2.4485  1.0138        77    7        2    14\n",
       "25785263  2.2503  1.3005        66    7        2     5\n",
       "18005463  2.0899  1.1891        72    3        5    14\n",
       "17892524  2.4850  1.4253        54    9        4    13\n",
       "10356407  2.4246  1.2065        62    5        0    16\n",
       "...          ...     ...       ...  ...      ...   ...\n",
       "6573759   2.3887  1.3054        29    4        6    17\n",
       "17184298  2.3864  1.0222        65    9        4    21\n",
       "3047468   2.3707  1.4906        66    6        1    10\n",
       "26133408  2.0718  1.1736       201    9        4    10\n",
       "23864929  2.3936  1.1778        72    7        2     1\n",
       "\n",
       "[60682 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------以下为特征工程部分----------\n",
    "#数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler     #特征预处理\n",
    "from sklearn.neighbors import KNeighborsClassifier  #机器学习算法\n",
    "from sklearn.model_selection import GridSearchCV  #特征降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征工程：特征预处理－标准化\n",
    "transfer =StandardScaler()\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict:\n",
      " [6438240873 7810150060 7038685199 ... 1663763627 1663763627 2607294907]\n",
      "直接比对真实值和预测值:\n",
      " 26165420     True\n",
      "12759338    False\n",
      "18740715    False\n",
      "3509883     False\n",
      "1168648     False\n",
      "            ...  \n",
      "21462544     True\n",
      "11946677    False\n",
      "11755634     True\n",
      "10429475     True\n",
      "24300335    False\n",
      "Name: place_id, Length: 20228, dtype: bool\n",
      "准确率为:\n",
      " 0.3649396875617955\n",
      "最佳参数:\n",
      " {'n_neighbors': 5}\n",
      "最佳结果:\n",
      " 0.33579974292211856\n",
      "最佳估计器:\n",
      " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "#-----以下为机器学习算法部分-----\n",
    "#knn算法预估器\n",
    "estimator = KNeighborsClassifier()\n",
    "\n",
    "#加入网格搜索与交叉验证\n",
    "#参数准备\n",
    "param_dict = {'n_neighbors':[3,5,7]}\n",
    "estimator = GridSearchCV(estimator,param_grid=param_dict,cv=3)\n",
    "estimator.fit(x_train,y_train)\n",
    "\n",
    "#模型评估\n",
    "#方法１：直接比对真实值和预测值\n",
    "y_predict = estimator.predict(x_test)\n",
    "print('y_predict:\\n',y_predict)\n",
    "print('直接比对真实值和预测值:\\n',y_test == y_predict)\n",
    "\n",
    "#方法２：计算准确率\n",
    "score = estimator.score(x_test,y_test)\n",
    "print('准确率为:\\n',score)\n",
    "\n",
    "#最佳参数：best_params\n",
    "print('最佳参数:\\n',estimator.best_params_)\n",
    "#最佳结果\n",
    "print('最佳结果:\\n',estimator.best_score_)\n",
    "#最佳估计器:best_estimator\n",
    "print('最佳估计器:\\n',estimator.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 朴素贝叶斯算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 朴素贝叶斯算法案例：２０类新闻分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路：\n",
    "1. 获取数据(sklearn内置的大样本数据集)\n",
    "2. 划分数据集\n",
    "3. 特征工程\n",
    "    文本特征抽取\n",
    "4. 朴素贝叶斯预估器流程\n",
    "5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups  #导入数据集\n",
    "#获取数据\n",
    "news = fetch_20newsgroups(subset='all')#subset='all'指明训练集和测试集都要\n",
    "\n",
    "#划分数据集\n",
    "x_train,x_test,y_train,y_test = train_test_split(news.data,news.target)\n",
    "#特征工程：文本特征抽取\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transfer = TfidfVectorizer()\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.transfer(x_test)\n",
    "#朴素贝叶斯算法预估器流程\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "estimator = MultinomialNB()\n",
    "estimator.fit(x_train,y_train)\n",
    "#模型评估\n",
    "#方法１：直接比对真实值和预测值\n",
    "y_predict = estimator.predict(x_test)\n",
    "print('y_predict:\\n',y_predict)\n",
    "print('直接比对真实值和预测值:n',y_test == y_predict)\n",
    "\n",
    "#方法２：计算准确率,将\n",
    "score = estimator.score(x_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
